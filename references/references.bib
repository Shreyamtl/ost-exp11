@article{Pea2023,
   abstract = {The presence of decision-making algorithms in society is rapidly increasing nowadays, while concerns about their transparency and the possibility of these algorithms becoming new sources of discrimination are arising. There is a certain consensus about the need to develop AI applications with a Human-Centric approach. Human-Centric Machine Learning needs to be developed based on four main requirements: (i) utility and social good; (ii) privacy and data ownership; (iii) transparency and accountability; and (iv) fairness in AI-driven decision-making processes. All these four Human-Centric requirements are closely related to each other. With the aim of studying how current multimodal algorithms based on heterogeneous sources of information are affected by sensitive elements and inner biases in the data, we propose a fictitious case study focused on automated recruitment: FairCVtest. We train automatic recruitment algorithms using a set of multimodal synthetic profiles including image, text, and structured data, which are consciously scored with gender and racial biases. FairCVtest shows the capacity of the Artificial Intelligence (AI) behind automatic recruitment tools built this way (a common practice in many other application scenarios beyond recruitment) to extract sensitive information from unstructured data and exploit it in combination to data biases in undesirable (unfair) ways. We present an overview of recent works developing techniques capable of removing sensitive information and biases from the decision-making process of deep learning architectures, as well as commonly used databases for fairness research in AI. We demonstrate how learning approaches developed to guarantee privacy in latent spaces can lead to unbiased and fair automatic decision-making process. Our methodology and results show how to generate fairer AI-based tools in general, and in particular fairer automated recruitment systems.},
   author = {Alejandro Pe√±a and Ignacio Serna and Aythami Morales and Julian Fierrez and Alfonso Ortega and Ainhoa Herrarte and Manuel Alcantara and Javier Ortega-Garcia},
   doi = {10.1007/s42979-023-01733-0},
   issn = {26618907},
   issue = {5},
   journal = {SN Computer Science},
   keywords = {Automated recruitment,Bias,Biometrics,Computer vision,Deep learning,FairCV,Fairness,Multimodal,Natural language processing},
   month = {9},
   publisher = {Springer},
   title = {Human-Centric Multimodal Machine Learning: Recent Advances and Testbed on AI-Based Recruitment},
   volume = {4},
   year = {2023}
}
@misc{Dadaboyev2025,
   abstract = {Artificial intelligence (AI) is increasingly used in recruitment processes to enhance efficiency and improve hiring decisions. This systematic literature review examines the opportunities and challenges of AI in employee recruitment across various organizational settings. Analyzing 49 peer-reviewed articles sourced from the Web of Science database published between 2018 and 2025, this review summarizes the current knowledge of AI's impact, highlighting its potential to increase productivity (e.g., through automated resume parsing and chatbot-led initial screening), improve candidate quality (e.g., via predictive analytics for job-fit and AI-assisted video interview analysis), and potentially reduce human bias by standardizing initial evaluations, though it also addresses critical ethical considerations such as the risk of algorithmic bias stemming from training data. However, it also addresses ethical considerations, including algorithmic bias and the need for transparency. The review concludes with recommendations for future research focused on legal frameworks, industry-specific applications, and mitigating the risks associated with AI in recruitment.},
   author = {Sherzodbek Murodilla Ugli Dadaboyev and Jasmina Abdullayeva and Naval Abbosova and Afina Suleymenova and Komila Mamadjanova},
   doi = {10.1007/s44282-025-00246-w},
   issn = {27319687},
   issue = {1},
   journal = {Discover Global Society},
   keywords = {Artificial intelligence (AI),Hiring,PRISMA,Recruitment,Systematic literature review},
   month = {12},
   publisher = {Discover},
   title = {Role of artificial intelligence in employee recruitment: systematic review and future research directions},
   volume = {3},
   year = {2025}
}
@inproceedings{Daryani2020,
   abstract = {A typical job posting on the Internet receives a massive number of applications within a short window of time. Manually filtering out the resumes is not practically possible as it takes a lot of time and incurs huge costs that the hiring companies cannot afford to bear. In addition, this process of screening resumes is not fair as many suitable profiles don't get enough consideration which they deserve. This may result in missing out on the right candidates or selection of unsuitable applicants for the job. In this paper, we describe a solution that aims to solve these issues by automatically suggesting the most appropriate candidates according to the given job description. Our system uses Natural Language Processing to extract relevant information like skills, education, experience, etc. from the unstructured resumes and hence creates a summarised form of each application. With all the irrelevant information removed, the task of screening is simplified and recruiters are able to better analyse each resume in less time. After this text mining process is completed, the proposed solution employs a vectorisation model and uses cosine similarity to match each resume with the job description. The calculated ranking scores can then be utilised to determine best-fitting candidates for that particular job opening.},
   author = {Chirag Daryani and Gurneet Singh Chhabra and Harsh Patel and Indrajeet Kaur Chhabra and Ruchi Patel},
   doi = {10.26480/etit.02.2020.99.103},
   month = {1},
   pages = {99-103},
   publisher = {ZIbeline International Publishing},
   title = {AN AUTOMATED RESUME SCREENING SYSTEM USING NATURAL LANGUAGE PROCESSING AND SIMILARITY},
   year = {2020}
}
